AAT: |
  Art & Architecture Thesaurus ist ein strukturiertes Vokabular des Getty Research Institute für Kunst-, Architektur- und Kulturgeschichte. Bietet hierarchisch organisierte Begriffe und mehrsprachige Synonyme für die konsistente Beschreibung kultureller Objekte.

API: |
  Application Programming Interfaces sind Schnittstellen zwischen verschiedenen Softwareanwendungen, die den strukturierten Datenaustausch ermöglichen. In der Metadatenpraxis wichtig für die automatisierte Übertragung und Synchronisation von Datenbeständen.

Authority Files: |
  Siehe Normdaten.

Bias: |
  Systematische Verzerrung oder Voreingenommenheit in Daten, Algorithmen oder Entscheidungsprozessen. Kann in verschiedenen Formen auftreten (Messfehler, Stichprobenfehler, algorithmischer Bias) und führt zu ungleicher Repräsentation oder Behandlung bestimmter Gruppen.

CARE-Prinzipien: |
  Ethische Grundsätze für Forschungsdaten indigener und marginalisierter Gemeinschaften. Collective Benefit (Kollektiver Nutzen), Authority to Control (Kontrollbefugnis), Responsibility (Verantwortung), Ethics (Ethik). Ergänzen die FAIR-Prinzipien um Aspekte der Datensouveränität.

CER: |
  Character Error Rate ist die Fehlerrate bei der automatischen Texterkennung (OCR/HTR), gemessen als Anteil falsch erkannter Zeichen. Wichtige Metrik zur Bewertung der Qualität digitalisierter Texte.

CIDOC-CRM: |
  Conceptual Reference Model ist ein internationaler Standard (ISO 21127) für die konzeptuelle Modellierung von Kulturerbe-Informationen. Ermöglicht die semantische Verknüpfung heterogener Datenquellen aus Museen, Archiven und Bibliotheken.

Controlled Vocabulary: |
  Siehe Kontrolliertes Vokabular.

Crowdsourcing: |
  Einbeziehung der Öffentlichkeit in Forschungs- oder Digitalisierungsprojekte, zum Beispiel bei der Transkription historischer Dokumente. Kann zur Demokratisierung der Wissensproduktion beitragen, birgt aber auch Risiken bezüglich Qualität und Bias.

CSV: |
  Comma-Separated Values ist ein einfaches, textbasiertes Dateiformat zur strukturierten Speicherung tabellarischer Daten. Weit verbreitet für den Datenaustausch zwischen verschiedenen Systemen.

Datenlebenszyklus: |
  Phasenmodell der Forschungsdatenverarbeitung von der Planung über Sammlung, Verarbeitung, Speicherung, Veröffentlichung und Nachnutzung bis zur Archivierung oder Löschung. Grundlage für systematisches Forschungsdatenmanagement.

DDB: |
  Deutsche Digitale Bibliothek ist eine zentrale Plattform für das kulturelle Erbe Deutschlands, die Millionen von Objekten aus über 4.000 Kultur- und Wissenschaftseinrichtungen vernetzt zugänglich macht.

Digital Humanities: |
  Interdisziplinäres Forschungsfeld, das digitale Methoden und Technologien in den Geisteswissenschaften anwendet. Umfasst Bereiche wie digitale Editionen, Korpusanalyse, Netzwerkforschung und Datenvisualisierung.

Diskriminierung: |
  Systematische Benachteiligung von Personen oder Gruppen aufgrund bestimmter Merkmale (Geschlecht, Herkunft, Religion etc.). Kann direkt, indirekt, strukturell oder institutionell auftreten und manifestiert sich auch in Daten- und Metadatenstrukturen.

Dublin Core: |
  Weit verbreiteter Metadatenstandard mit 15 Kernelementen (Title, Creator, Subject, Description, Publisher, Contributor, Date, Type, Format, Identifier, Source, Language, Relation, Coverage, Rights) zur grundlegenden Beschreibung digitaler Ressourcen.

EAD: |
  Encoded Archival Description ist ein XML-Standard für die strukturierte Beschreibung von Archivbeständen. Ermöglicht hierarchische Darstellung von Findmitteln und unterstützt komplexe Provenienz- und Kontextinformationen.

EDM: |
  Europeana Data Model ist das Datenmodell der Europeana für die Aggregation und Bereitstellung europäischer Kulturobjekte. Basiert auf Linked Data-Prinzipien und ermöglicht semantische Verknüpfungen zwischen verschiedenen Sammlungen.

EDTF: |
  Extended Date/Time Format ist ein Standard für die Darstellung unsicherer, approximativer oder komplexer Datumsangaben in historischen Quellen. Unterstützt Zeiträume, Unsicherheitsmarkierungen und alternative Kalendersysteme.

Entity Resolution: |
  Automatisiertes Verfahren zur Identifikation und Zusammenführung von Datensätzen, die sich auf dieselbe Entität (Person, Ort, Organisation) beziehen. Zentral für die Erstellung konsistenter Normdaten.

FAIR-Prinzipien: |
  Grundsätze für Forschungsdatenmanagement. Findable (Auffindbar), Accessible (Zugänglich), Interoperable (Interoperabel), Reusable (Nachnutzbar). Fördern die offene und nachhaltige Nutzung wissenschaftlicher Daten.

Fine-Tuning: |
  Anpassung vortrainierter Machine Learning-Modelle an spezifische Datensätze oder Aufgaben. In der Metadatenpraxis relevant für OCR/HTR-Verbesserung oder Named Entity Recognition.

Forschungsdatenmanagement: |
  Systematische Organisation, Dokumentation und Bereitstellung von Forschungsdaten während des gesamten Forschungsprozesses. Umfasst technische, rechtliche und ethische Aspekte.

GLAM: |
  Galleries, Libraries, Archives, Museums ist ein Sammelbegriff für Gedächtnisinstitutionen, die kulturelles Erbe sammeln, bewahren und zugänglich machen.

GND: |
  Gemeinsame Normdatei ist eine kooperativ gepflegte Normdatei deutschsprachiger Bibliotheken für Personen, Körperschaften, Kongresse, Geografika, Sachschlagwörter und Werktitel. Zentrale Infrastruktur für die Vernetzung bibliographischer Daten.

HTR: |
  Handwritten Text Recognition ist die automatische Erkennung handschriftlicher Texte mittels Machine Learning. Spezialisierte Weiterentwicklung der OCR-Technologie für historische Handschriften und Dokumente.

IIIF: |
  International Image Interoperability Framework sind Standards für die interoperable Bereitstellung von Bildern und audiovisuellen Medien. Ermöglicht einheitliche Darstellung, Annotation und Manipulation digitaler Objekte unabhängig vom Hosting-System.

Interoperabilität: |
  Fähigkeit verschiedener Systeme, Daten und Funktionalitäten nahtlos auszutauschen. In der Metadatenpraxis durch gemeinsame Standards, Vokabulare und Protokolle realisiert.

ISO: |
  International Organization for Standardization ist eine internationale Organisation für Normung, die technische Standards für verschiedene Bereiche entwickelt, einschließlich Informationsmanagement und Dokumentation.

JSON: |
  JavaScript Object Notation ist ein leichtgewichtiges, textbasiertes Datenformat für den strukturierten Datenaustausch. Weit verbreitet in Web-APIs und zunehmend auch für Metadaten verwendet.

JSON-LD: |
  JSON for Linking Data ist eine Erweiterung von JSON für Linked Data-Anwendungen. Ermöglicht die semantische Annotation von JSON-Strukturen durch Verweise auf kontrollierte Vokabulare.

Kontrolliertes Vokabular: |
  Festgelegte Sammlung von Begriffen zur konsistenten Indexierung und Beschreibung von Inhalten. Umfasst Synonyme, hierarchische Beziehungen und Verwendungsregeln.

LCSH: |
  Library of Congress Subject Headings ist ein umfangreiches, hierarchisch strukturiertes Schlagwortsystem der Library of Congress. Internationaler Standard für die sachliche Erschließung in Bibliotheken.

LIDO: |
  Lightweight Information Describing Objects ist ein XML-Schema für die Beschreibung von Museumsobjekten. Ermöglicht detaillierte Erfassung von Provenienz, Materialien, Techniken und kulturhistorischen Kontexten.

Linked Data: |
  Methode zur strukturierten Veröffentlichung und Verknüpfung von Daten im World Wide Web. Basiert auf RDF und URI-Standards und ermöglicht die automatisierte Verarbeitung semantischer Beziehungen.

LOUD: |
  Linked Open Usable Data ist eine Weiterentwicklung der Linked Data-Prinzipien mit Fokus auf praktische Nutzbarkeit. Betont entwicklerfreundliche APIs, JSON-LD-Format und ausführliche Dokumentation.

MARC: |
  Machine-Readable Cataloging ist ein internationaler Standard für die maschinelle Verarbeitung bibliographischer Daten. Grundlage der meisten Bibliothekskataloge, zunehmend durch flexiblere RDF-basierte Formate ergänzt.

Metadaten: |
  Strukturierte Informationen, die andere Daten beschreiben und kontextualisieren. Umfassen bibliographische, administrative, strukturelle und Bewahrungsmetadaten. Zentral für Auffindbarkeit und Nachnutzbarkeit digitaler Ressourcen.

METS: |
  Metadata Encoding and Transmission Standard ist ein XML-Schema für die Strukturierung und Verknüpfung von Metadaten digitaler Objekte. Weit verbreitet in digitalen Bibliotheken und Archiven.

Named Entity Recognition: |
  Automatisierte Identifikation und Klassifikation von Entitäten (Personen, Orte, Organisationen) in Texten. Wichtig für die Anreicherung von Metadaten und die Verknüpfung mit Normdaten.

Normdaten: |
  Authoritative Verzeichnisse eindeutiger Bezeichnungen für Personen, Körperschaften, Orte, Sachbegriffe oder Werke. Ermöglichen konsistente Verknüpfung und Auffindbarkeit von Informationen über verschiedene Systeme hinweg.

Normativität: |
  Eigenschaft von Regeln, Standards oder Kategorien, bestimmte Ordnungen als normal oder wünschenswert zu etablieren. In der Metadatenpraxis oft unsichtbar, aber wirkmächtig bei der Strukturierung von Wissen.

OAI-PMH: |
  Open Archives Initiative Protocol for Metadata Harvesting ist ein Protokoll für die automatisierte Sammlung von Metadaten aus verteilten Repositorien. Ermöglicht die Aggregation von Metadaten ohne Duplikation der eigentlichen Inhalte.

OAIS: |
  Open Archival Information System ist ein Referenzmodell für digitale Langzeitarchivierung (ISO 14721). Definiert Rollen, Funktionen und Informationsmodelle für vertrauenswürdige digitale Repositorien.

OCR: |
  Optical Character Recognition ist die automatische Erkennung von Zeichen in digitalisierten Texten. Grundlage für die Volltextsuche in historischen Dokumenten, unterliegt aber systematischen Fehlern bei historischen Schriften.

Ontologie: |
  Formale Beschreibung von Konzepten und ihren Beziehungen in einem bestimmten Wissensbereich. In der Metadatenpraxis Grundlage für semantische Verknüpfungen und automatisierte Inferenzen.

Open Access: |
  Freier, unentgeltlicher und dauerhafter Zugang zu wissenschaftlichen Informationen. Umfasst sowohl Publikationen als auch Forschungsdaten und unterstützt die demokratische Teilhabe am wissenschaftlichen Diskurs.

Oppression: |
  Systematische Unterdrückung bestimmter Gruppen durch ineinandergreifende Praktiken, Diskurse und Institutionen. Manifestiert sich auch in Datenstrukturen und Klassifikationssystemen.

PREMIS: |
  Preservation Metadata Implementation Strategies ist ein Datenmodell für Bewahrungsmetadaten in digitalen Archiven. Dokumentiert Herkunft, Authentizität, Bewahrungsaktivitäten und technische Eigenschaften digitaler Objekte.

Provenienz: |
  Dokumentation der Herkunft, Geschichte und Veränderungen von Daten oder Objekten. In der digitalen Forschung essentiell für Nachvollziehbarkeit und Vertrauenswürdigkeit.

Query Expansion: |
  Automatische Erweiterung von Suchanfragen durch semantisch verwandte Begriffe. Verbessert die Vollständigkeit von Suchergebnissen, besonders bei heterogenen Metadaten.

RDF: |
  Resource Description Framework ist ein Standard des World Wide Web Consortium für die strukturierte Beschreibung von Ressourcen. Grundlage des Semantic Web und von Linked Data-Anwendungen.

Record Linkage: |
  Siehe Entity Resolution.

Repository: |
  Digitales Archiv zur systematischen Sammlung, Speicherung und Bereitstellung von Forschungsdaten oder Publikationen. Unterstützt typischerweise Metadatenstandards, persistente Identifikatoren und Such- und Zugriffsfunktionen.

Schema: |
  Strukturelle Beschreibung der erlaubten Elemente, Attribute und Beziehungen in einem Datenformat. Definiert Regeln für die Validierung und Interpretation von Metadaten.

Semantic Web: |
  Vision eines maschinenlesbaren World Wide Web, in dem Daten semantisch annotiert und automatisch verarbeitet werden können. Basiert auf Standards wie RDF, SPARQL und Ontologien.

SKOS: |
  Simple Knowledge Organization System ist ein Standard für die Repräsentation von Klassifikationssystemen, Thesauri und anderen kontrollierten Vokabularen als Linked Data. Ermöglicht die Verknüpfung verschiedener Begriffssysteme.

TEI: |
  Text Encoding Initiative ist ein internationaler Standard für die digitale Kodierung literarischer und historischer Texte. Basiert auf XML und ermöglicht detaillierte strukturelle und inhaltliche Annotation.

Topic Modeling: |
  Computergestützte Methode zur automatischen Identifikation thematischer Muster in Textsammlungen. Hilfreich für die Analyse großer Korpora, erfordert aber kritische Interpretation der Ergebnisse.

VIAF: |
  Virtual International Authority File ist eine internationale Normdatei, die Normdaten von Nationalbibliotheken weltweit verknüpft. Ermöglicht die eindeutige Identifikation von Personen und Körperschaften über Sprachgrenzen hinweg.

VRA Core: |
  Visual Resources Association Core ist ein Metadatenstandard für die Beschreibung visueller Kulturobjekte. Speziell entwickelt für Bilder, Kunstwerke und architektonische Objekte.

WER: |
  Word Error Rate ist die Fehlerrate bei der automatischen Texterkennung, gemessen als Anteil falsch erkannter Wörter. Ergänzt die Character Error Rate (CER) bei der Bewertung von OCR/HTR-Qualität.

XML: |
  eXtensible Markup Language ist eine strukturierte Auszeichnungssprache für die plattformunabhängige Darstellung hierarchisch organisierter Daten. Grundlage vieler Metadatenstandards wie METS, EAD und TEI.

Authority Control: |
  Siehe Normdatenkontrolle.

Crosswalk: |
  Verfahren zur Zuordnung von Datenelementen zwischen verschiedenen Metadatenstandards. Ermöglicht die Migration und Interoperabilität von Metadaten.

Faceted Classification: |
  Mehrperspektivische Klassifikation, die Objekte nach verschiedenen unabhängigen Aspekten (Facetten) ordnet. Ermöglicht flexible Kombination von Suchkriterien.

Granularität: |
  Detailgrad der Datenerfassung und -beschreibung. Betrifft sowohl die Strukturierung von Objekten als auch die Tiefe der Metadatenannötiation.

Metadatenharvesting: |
  Siehe OAI-PMH.

Multilingual Access: |
  Mehrsprachiger Zugang zu digitalen Ressourcen durch übersetzt oder parallele Metadaten. Wichtig für die internationale Nutzbarkeit von Kulturerbe-Daten.

Thesaurus: |
  Hierarchisch strukturiertes, kontrolliertes Vokabular mit definierten Beziehungen zwischen Begriffen (broader/narrower terms, related terms). Unterstützt sowohl die Indexierung als auch die Suche.

Workflow: |
  Systematische Abfolge von Arbeitsschritten in der Datenverarbeitung. In der Metadatenpraxis wichtig für Qualitätssicherung und Konsistenz.
